import json
import re
import os

# è¨­å®šé¡åˆ¥æ¬Šé‡ (å¯ä¾éœ€æ±‚èª¿æ•´)
ALPHA_COST = 2.0  # è©é¨™æ¨£æœ¬ (True) çš„æ¬Šé‡ (æ¼å ±ä»£åƒ¹å¤§)
BETA_COST = 1.0   # æ­£å¸¸æ¨£æœ¬ (False) çš„æ¬Šé‡

def calculate_dwa_from_jsonl(file_path):
    """
    å¾ JSONL æª”æ¡ˆè®€å–è³‡æ–™ä¸¦è¨ˆç®—è¡°æ¸›åŠ æ¬Šæº–ç¢ºç‡ (DWA Score)
    
    åƒæ•¸:
    file_path (str): jsonl æª”æ¡ˆçš„è·¯å¾‘
    """
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        return

    parsed_results = []
    global_max_len = 0
    valid_count = 0
    
    print(f"æ­£åœ¨è®€å–æª”æ¡ˆ: {file_path} ...")
    
    # ---------------------------------------------------------
    # æ­¥é©Ÿ 1: è®€å–æª”æ¡ˆä¸¦é è™•ç†
    # ---------------------------------------------------------
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_idx, line in enumerate(f):
                line = line.strip()
                if not line: continue 
                
                try:
                    item = json.loads(line)
                except json.JSONDecodeError:
                    print(f"[Warning] Line {line_idx+1} is not valid JSON. Skipped.")
                    continue

                # --- A. æå–å°è©±é•·åº¦ ---
                user_content = ""
                if 'messages' in item and isinstance(item['messages'], list):
                    for msg in item['messages']:
                        if msg.get('role') == 'user':
                            user_content = msg.get('content', "")
                            break
                
                match = re.search(r'<conversation>(.*?)</conversation>', user_content, re.DOTALL)
                if match:
                    actual_conversation = match.group(1).strip()
                else:
                    actual_conversation = user_content
                
                length = len(actual_conversation)
                if length > global_max_len:
                    global_max_len = length
                
                # --- B. åˆ¤æ–·ç­”å°èˆ‡å¦ ---
                prediction = str(item.get('response', '')).strip()
                
                if 'labels' in item:
                    ground_truth = str(item['labels']).strip()
                elif 'label' in item:
                    ground_truth = str(item['label']) 
                else:
                    ground_truth = "Unknown"

                is_correct = (prediction.lower() == ground_truth.lower())
                
                parsed_results.append({
                    'line_no': line_idx + 1,
                    'length': length,
                    'is_correct': is_correct,
                    'prediction': prediction,
                    'ground_truth': ground_truth
                })
                valid_count += 1
                
    except Exception as e:
        print(f"è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return

    if valid_count == 0:
        print("æ²’æœ‰è®€å–åˆ°æœ‰æ•ˆè³‡æ–™ã€‚")
        return

    # ---------------------------------------------------------
    # æ­¥é©Ÿ 2: è¨ˆç®— DWA åˆ†æ•¸ (ä¿®æ”¹è™•)
    # ---------------------------------------------------------
    epsilon = 1e-9
    total_weighted_score = 0  
    total_possible_weight = 0 
    
    for i, res in enumerate(parsed_results):
        L = res['length']
        
        # 1. è¨ˆç®—é•·åº¦è¡°æ¸›æ¬Šé‡ (w_len)
        w_len = 1.0 - (L / (global_max_len + epsilon))
        w_len = max(0.0, w_len) 
        
        # 2. è¨ˆç®—é¡åˆ¥æˆæœ¬æ¬Šé‡ (w_class) [æ–°å¢]
        # åˆ¤æ–· Ground Truth æ˜¯å¦ç‚ºè©é¨™ (True)
        is_fraud_sample = (res['ground_truth'].lower() == 'true' or res['ground_truth'] == '1')
        w_class = ALPHA_COST if is_fraud_sample else BETA_COST
        
        # 3. çµåˆæ¬Šé‡ (Omega) [ä¿®æ”¹]
        final_weight = w_len * w_class
        
        # 4. ç´¯åŠ åˆ†æ•¸
        contribution = final_weight if res['is_correct'] else 0.0
        
        total_weighted_score += contribution
        total_possible_weight += final_weight

    # ---------------------------------------------------------
    # æ­¥é©Ÿ 3: æœ€çµ‚çµ±è¨ˆ
    # ---------------------------------------------------------
    if total_possible_weight == 0:
        final_score = 0.0
    else:
        final_score = total_weighted_score / total_possible_weight

    print("=" * 80)
    print(f"ğŸ“Š çµ±è¨ˆæ‘˜è¦ (DWA Metric):")
    print(f"   - åƒæ•¸è¨­å®š:          Alpha(Fraud)={ALPHA_COST}, Beta(Normal)={BETA_COST}")
    print(f"   - ç¸½æ¨£æœ¬æ•¸ (N):      {valid_count}")
    print(f"   - å…¨åŸŸæœ€å¤§é•·åº¦ (Max): {global_max_len} chars")
    print(f"   - åŠ æ¬Šç¸½åˆ† (Num):    {total_weighted_score:.4f}")
    print(f"   - ç¸½æ¬Šé‡ (Denom):    {total_possible_weight:.4f}")
    print("-" * 80)
    print(f"ğŸ¯ DWA Score (è¡°æ¸›åŠ æ¬Šæº–ç¢ºç‡): {final_score:.4f}")
    print("=" * 80)
    
    return final_score


def qwen_8b_calculate_dwa_from_jsonl(file_path):
    """
    [Qwenç‰ˆ] å¾ JSONL æª”æ¡ˆè®€å–è³‡æ–™ä¸¦è¨ˆç®—è¡°æ¸›åŠ æ¬Šæº–ç¢ºç‡ (DWA Score)
    """
    
    if not os.path.exists(file_path):
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        return

    parsed_results = []
    global_max_len = 0
    valid_count = 0
    
    print(f"æ­£åœ¨è®€å–æª”æ¡ˆ: {file_path} ...")
    
    # ---------------------------------------------------------
    # æ­¥é©Ÿ 1: è®€å–æª”æ¡ˆä¸¦é è™•ç†
    # ---------------------------------------------------------
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_idx, line in enumerate(f):
                line = line.strip()
                if not line: continue
                
                try:
                    item = json.loads(line)
                except json.JSONDecodeError:
                    print(f"[Warning] Line {line_idx+1} is not valid JSON. Skipped.")
                    continue

                # --- A. æå–å°è©±é•·åº¦ ---
                user_content = ""
                if 'messages' in item and isinstance(item['messages'], list):
                    for msg in item['messages']:
                        if msg.get('role') == 'user':
                            user_content = msg.get('content', "")
                            break
                
                match = re.search(r'<conversation>(.*?)</conversation>', user_content, re.DOTALL)
                if match:
                    actual_conversation = match.group(1).strip()
                else:
                    actual_conversation = user_content
                
                length = len(actual_conversation)
                if length > global_max_len:
                    global_max_len = length
                
                # --- B. åˆ¤æ–·ç­”å°èˆ‡å¦ (Qwen ç‰¹æ®Šè™•ç†) ---
                raw_response = str(item.get('response', '')).strip()
                prediction_text = re.sub(r'<think>.*?</think>', '', raw_response, flags=re.DOTALL).strip()
                
                prediction_match = re.search(r'[01]', prediction_text)
                if prediction_match:
                    prediction = prediction_match.group(0)
                else:
                    prediction = prediction_text[:10] if prediction_text else "Unknown"
                
                if 'labels' in item:
                    ground_truth = str(item['labels']).strip()
                elif 'label' in item:
                    ground_truth = str(item['label']).strip()
                else:
                    ground_truth = "Unknown"

                is_correct = (prediction.lower() == ground_truth.lower())
                
                parsed_results.append({
                    'line_no': line_idx + 1,
                    'length': length,
                    'is_correct': is_correct,
                    'prediction': prediction,
                    'ground_truth': ground_truth
                })
                valid_count += 1
                
    except Exception as e:
        print(f"è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return

    if valid_count == 0:
        print("æ²’æœ‰è®€å–åˆ°æœ‰æ•ˆè³‡æ–™ã€‚")
        return

    # ---------------------------------------------------------
    # æ­¥é©Ÿ 2: è¨ˆç®— DWA åˆ†æ•¸ (ä¿®æ”¹è™•)
    # ---------------------------------------------------------
    epsilon = 1e-9
    total_weighted_score = 0  
    total_possible_weight = 0 
    
    for i, res in enumerate(parsed_results):
        L = res['length']
        
        # 1. é•·åº¦è¡°æ¸›
        w_len = 1.0 - (L / (global_max_len + epsilon))
        w_len = max(0.0, w_len)
        
        # 2. é¡åˆ¥æˆæœ¬ [æ–°å¢]
        # æ³¨æ„ï¼šQwen ç‰ˆæœ¬çš„ Ground Truth å¯èƒ½æ˜¯ "0"/"1" æˆ– "True"/"False"
        gt_str = res['ground_truth'].lower()
        is_fraud_sample = (gt_str == 'true' or gt_str == '1')
        w_class = ALPHA_COST if is_fraud_sample else BETA_COST
        
        # 3. çµåˆæ¬Šé‡
        final_weight = w_len * w_class
        
        contribution = final_weight if res['is_correct'] else 0.0
        
        total_weighted_score += contribution
        total_possible_weight += final_weight

    # ---------------------------------------------------------
    # æ­¥é©Ÿ 3: æœ€çµ‚çµ±è¨ˆ
    # ---------------------------------------------------------
    if total_possible_weight == 0:
        final_score = 0.0
    else:
        final_score = total_weighted_score / total_possible_weight

    print("=" * 80)
    print(f"ğŸ“Š çµ±è¨ˆæ‘˜è¦ (DWA Metric - Qwen):")
    print(f"   - åƒæ•¸è¨­å®š:          Alpha(Fraud)={ALPHA_COST}, Beta(Normal)={BETA_COST}")
    print(f"   - ç¸½æ¨£æœ¬æ•¸ (N):      {valid_count}")
    print(f"   - å…¨åŸŸæœ€å¤§é•·åº¦ (Max): {global_max_len} chars")
    print(f"   - åŠ æ¬Šç¸½åˆ† (Num):    {total_weighted_score:.4f}")
    print(f"   - ç¸½æ¬Šé‡ (Denom):    {total_possible_weight:.4f}")
    print("-" * 80)
    print(f"ğŸ¯ DWA Score (è¡°æ¸›åŠ æ¬Šæº–ç¢ºç‡): {final_score:.4f}")
    print("=" * 80)
    
    return final_score


def oss_calculate_dwa_from_jsonl(file_path):
    """
    [OSSç‰ˆ] å¾ JSONL æª”æ¡ˆè®€å–è³‡æ–™ä¸¦è¨ˆç®—è¡°æ¸›åŠ æ¬Šæº–ç¢ºç‡ (DWA Score)
    """
    
    if not os.path.exists(file_path):
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        return

    parsed_results = []
    global_max_len = 0
    valid_count = 0
    no_match_count = 0
    
    print(f"æ­£åœ¨è®€å–æª”æ¡ˆ: {file_path} ...")
    
    # ---------------------------------------------------------
    # æ­¥é©Ÿ 1: è®€å–æª”æ¡ˆä¸¦é è™•ç†
    # ---------------------------------------------------------
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_idx, line in enumerate(f):
                line = line.strip()
                if not line: continue
                
                try:
                    item = json.loads(line)
                except json.JSONDecodeError:
                    print(f"[Warning] Line {line_idx+1} is not valid JSON. Skipped.")
                    continue

                # --- A. æå–å°è©±é•·åº¦ ---
                user_content = ""
                if 'messages' in item and isinstance(item['messages'], list):
                    for msg in item['messages']:
                        if msg.get('role') == 'user':
                            user_content = msg.get('content', "")
                            break
                
                match = re.search(r'<conversation>(.*?)</conversation>', user_content, re.DOTALL)
                if match:
                    actual_conversation = match.group(1).strip()
                else:
                    actual_conversation = user_content
                
                length = len(actual_conversation)
                if length > global_max_len:
                    global_max_len = length
                
                # --- B. åˆ¤æ–·ç­”å°èˆ‡å¦ (OSS ç‰¹æ®Šè™•ç†) ---
                raw_response = str(item.get('response', '')).strip()
                true_false_matches = list(re.finditer(r'\b(True|False)\b', raw_response, re.IGNORECASE))
                
                if true_false_matches:
                    last_match = true_false_matches[-1]
                    prediction = last_match.group(1)
                else:
                    prediction = "Unknown"
                    no_match_count += 1
                
                if 'labels' in item:
                    ground_truth = str(item['labels']).strip()
                elif 'label' in item:
                    label_val = item['label']
                    if label_val == 0:
                        ground_truth = "False"
                    elif label_val == 1:
                        ground_truth = "True"
                    else:
                        ground_truth = str(label_val)
                else:
                    ground_truth = "Unknown"

                is_correct = (prediction.lower() == ground_truth.lower())
                
                parsed_results.append({
                    'line_no': line_idx + 1,
                    'length': length,
                    'is_correct': is_correct,
                    'prediction': prediction,
                    'ground_truth': ground_truth
                })
                valid_count += 1
                
    except Exception as e:
        print(f"è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return

    if valid_count == 0:
        print("æ²’æœ‰è®€å–åˆ°æœ‰æ•ˆè³‡æ–™ã€‚")
        return

    if no_match_count > 0:
        print(f"âš ï¸  è­¦å‘Š: æœ‰ {no_match_count} ç­†è³‡æ–™çš„ response ä¸­æœªæ‰¾åˆ° True æˆ– False")

    # ---------------------------------------------------------
    # æ­¥é©Ÿ 2: è¨ˆç®— DWA åˆ†æ•¸ (ä¿®æ”¹è™•)
    # ---------------------------------------------------------
    epsilon = 1e-9
    total_weighted_score = 0  
    total_possible_weight = 0 
    
    for i, res in enumerate(parsed_results):
        L = res['length']
        
        # 1. é•·åº¦è¡°æ¸›
        w_len = 1.0 - (L / (global_max_len + epsilon))
        w_len = max(0.0, w_len)
        
        # 2. é¡åˆ¥æˆæœ¬ [æ–°å¢]
        # åˆ¤æ–· Ground Truth æ˜¯å¦ç‚ºè©é¨™ (True)
        gt_str = res['ground_truth'].lower()
        is_fraud_sample = (gt_str == 'true' or gt_str == '1')
        w_class = ALPHA_COST if is_fraud_sample else BETA_COST
        
        # 3. çµåˆæ¬Šé‡
        final_weight = w_len * w_class
        
        contribution = final_weight if res['is_correct'] else 0.0
        
        total_weighted_score += contribution
        total_possible_weight += final_weight

    # ---------------------------------------------------------
    # æ­¥é©Ÿ 3: æœ€çµ‚çµ±è¨ˆ
    # ---------------------------------------------------------
    if total_possible_weight == 0:
        final_score = 0.0
    else:
        final_score = total_weighted_score / total_possible_weight

    correct_count = sum(1 for res in parsed_results if res['is_correct'])
    accuracy = correct_count / valid_count if valid_count > 0 else 0.0

    print("=" * 80)
    print(f"ğŸ“Š çµ±è¨ˆæ‘˜è¦ (DWA Metric - OSS):")
    print(f"   - åƒæ•¸è¨­å®š:          Alpha(Fraud)={ALPHA_COST}, Beta(Normal)={BETA_COST}")
    print(f"   - ç¸½æ¨£æœ¬æ•¸ (N):      {valid_count}")
    print(f"   - ç­”å°æ•¸é‡:          {correct_count}")
    print(f"   - å‚³çµ±æº–ç¢ºç‡:        {accuracy:.4f}")
    print(f"   - å…¨åŸŸæœ€å¤§é•·åº¦ (Max): {global_max_len} chars")
    print(f"   - åŠ æ¬Šç¸½åˆ† (Num):    {total_weighted_score:.4f}")
    print(f"   - ç¸½æ¬Šé‡ (Denom):    {total_possible_weight:.4f}")
    print("-" * 80)
    print(f"ğŸ¯ DWA Score (è¡°æ¸›åŠ æ¬Šæº–ç¢ºç‡): {final_score:.4f}")
    print("=" * 80)
    
    return final_score

"""
print("base_8b")
calculate_cdi_from_jsonl("./inference_data/base_8b_infer_all_test_results.jsonl")
print("sft_8b")
calculate_cdi_from_jsonl("./inference_data/sft_8b_infer_all_test_results_50_v3.jsonl")
print("base_70b_awq")
calculate_cdi_from_jsonl("./inference_data/base_70b_awq_infer_all_test_results.jsonl")
print("qwen_8b")
qwen_8b_calculate_cdi_from_jsonl("./inference_data/qwen_8b_infer_all_test_results.jsonl")
print("ministral_8b")
calculate_cdi_from_jsonl("./inference_data/ministral_8b_infer_all_test_results.jsonl")
print("ministral_8b_v1_50")
calculate_cdi_from_jsonl("./inference_data/ministral_8b_infer_all_test_results_50_v1.jsonl")
print("ministral_8b_v1_81")
calculate_cdi_from_jsonl("./inference_data/ministral_8b_infer_all_test_results_81_v1.jsonl")
print("ministral_8b_v2_30")
calculate_cdi_from_jsonl("./inference_data/ministral_8b_infer_all_test_results_30_v2.jsonl")
"""
print("ministral_8b_v1_50")
calculate_dwa_from_jsonl("./inference_data/ministral_8b_infer_test_results_50_v1.jsonl")
print("ministral_8b_v1_81")
calculate_dwa_from_jsonl("./inference_data/ministral_8b_infer_test_results_81_v1.jsonl")
print("ministral_8b")
calculate_dwa_from_jsonl("./inference_data/ministral_8b_infer_test_results.jsonl")
print("qwen_8b")
qwen_8b_calculate_dwa_from_jsonl("./inference_data/qwen_8b_infer_test_results.jsonl")
print("qwen_32b")
qwen_8b_calculate_dwa_from_jsonl("./inference_data/qwen_32b_infer_test_results.jsonl")
print("base_8b")
calculate_dwa_from_jsonl("./inference_data/base_8b_infer_test_result.jsonl")
print("sft_8b")
calculate_dwa_from_jsonl("./inference_data/sft_8b_infer_test_results_50_v3.jsonl")
print("base_70b_awq")
calculate_dwa_from_jsonl("./inference_data/base_70b_awq_infer_test_results.jsonl")
print("gpt_120b")
oss_calculate_dwa_from_jsonl("./inference_data/gpt_120b_infer_test_results.jsonl")
print("sft_8b_v4")
calculate_dwa_from_jsonl("./inference_data/sft_8b_infer_test_results_20_v4.jsonl")
calculate_dwa_from_jsonl("./inference_data/sft_8b_infer_test_results_40_v4.jsonl")
calculate_dwa_from_jsonl("./inference_data/sft_8b_infer_test_results_60_v4.jsonl")
calculate_dwa_from_jsonl("./inference_data/sft_8b_infer_test_results_80_v4.jsonl")
calculate_dwa_from_jsonl("./inference_data/sft_8b_infer_test_results_100_v4.jsonl")
calculate_dwa_from_jsonl("./inference_data/sft_8b_infer_test_results_108_v4.jsonl")